---
layout: post
title:  "Understand AdaBoost"
date:   2017-09-27
categories: blog
---

# Understand AdaBoost

看了周志华的机器学习第八章集成学习Boosting部分，虽然作者说是用了比较容易理解的推导。但是有些东西在我看来还是不容易理解。下面按照机器学习的一般步骤记录一下我对AdaBoost算法的简单理解。

## Loss Function
AdaBoost基于“加法模型”，即基学习器的线性组合
$$H(x)=\sum_{t=1}^{T}\alpha_{t}h_{t}(x)$$

这一部分还是很好理解的。有了学习器，损失函数可以写为：

$$l_{exp}(H|D)=\mathbb{E}_{x~D}[e^{-f(x)H(x)}]$$

为了方便起见，把$f(x)$表示成$y$，其实写成$f(x)$，能够误导人，把这个期望展开后有一些困扰。另外，Friedman在论文里面也用的$y$ 。这和我一开始想的损失函数不同，一开始认为用$l=\mathbb{E}_{x~D}[-f(x)H(x)]$，就可以了，不过在下面算梯度，更新权值的时候就可以看到这样做的缺点，<del>至于原因可以见习题的分析</del>

## Update Parameters

在研究参数更新之前，我们先从另一个角度理解一下损失函数。



使损失函数最小化先对$H(x)$求偏导，

$$\frac{\partial{l_{exp}(H|D)}}{\partial{H(x)}}=e^{-H(x)}P(f(x)=1|x)+e^{H(x)}P(f(x)=-1|x)$$

这个公式我刚刚开始看的时候还觉得很对，不过越看越不对劲，这里面的$x$是向量，没见过这种表示，还是从期望的定义出发去得到这个式子吧。



首先要知道$\mathbb{E}_{x~D}$表示什么，书的最前面说表示在D分布下的期望，其实这样说还是有些玄学的，用简单的期望公式表达出来就是：

$$\mathbb{E}_{x~D}[f]=\sum_{i=1}^{n}P(X=x_{i})E(f|x_{i})$$

在书中$P(X=x_{i})$又被写成$D(x_{i})$ ，这在后面训练集比例更新时会有作用。这样解释了一下就很直观，不至于原文中那样会让人看了一脸懵逼。下面把$l_{exp}(H|D)$写成公式的形式：

$$l_{exp}(H|D)=\mathbb{E}_{x~D}(e^{-yH(x)})=\sum_{i=1}^{n}D(x_{i})E(e^{-yH(x_{i})}|x_{i})$$

有条件概率公式

$$E(e^{-yH(x_{i})}|x_{i})=\sum_{y}e^{-yH(x)}P(y|x_{i})=e^{-H(x_{i})}P(y=1|x_{i})+e^{H(x_{i})}P(y=-1|x_{i})$$

$min \text{ }l_{exp}$相当于$min\text{ }E(e^{-yH(x_{i})}|x_{i})$，相同的套路，对$E(e^{-yH(x_{i})}|x_{i})$求导

$$\frac{\partial{E(e^{-yH(x_{i})})}}{\partial{H(x_{i})}}=e^{-H(x_{i})}P(y=1|x_{i})+e^{H(x_{i})}P(y=-1|x_{i})$$

使导数为0，得到

$H(x_{i})=\frac{1}{2}\ln{\frac{P(y=1|x_{i})}{P(y=-1|x_{i})}}$

因此有

$$sign(H(x_{i}))=sign(\frac{1}{2}\ln{\frac{P(y=1|x_{i})}{P(y=-1|x_{i})}}) $$

解释一下上式，

当$P(y=1|x_{i})>P(y=-1|x_{i})$时，$sign(H(x))$的值为1，即正确分类。

当$P(y=-1|x_{i})>P(y=1|x_{i})$时，$sign(H(x))$的值为-1，即正确分类。



对$i=1,2,...n$均有上式成立，就最小化损失函数了。书上用向量形式表示，由于没看过矩阵求导那一套东西，觉得他那种写法很奇怪，分开来后从定义出发，直观很多，只要是稍微学过概率论的就可以看懂。



以上这些都说明了指数损失函数的合理性，如果按我一开始的想法，把损失函数写成$l(H|D)=\mathbb{E}_{x~D}[-yH(x)]$，看起来这个损失函数是没问题的，$y$和$H(x)$相同的越多，即正确分类越多，$l(H|D)$就越小。如果我也按上面的步骤求导，就会出现问题。



其他的推导和前面的差不多，我直接把期望对$H(x_{i})$的偏导数写出来

$$\frac{\partial{\mathbb{E}_{x~D}[-yH(x_{i})|x_{i}]}}{\partial{H(x_{i})}}=-H(x_{i})P(y=1|x_{i})+H(x_{i})P(y=-1|x_{i})$$

这个式子等于0时，得不到什么有效信息，至于为什么会这样，我也不是很清楚。下面进入下一部分，参数更新。



### Update $\alpha$

如果了解加法模型是如何学习的，在$t$次更新时，损失函数可以写成$l_{exp}(\alpha_{t}h_{t}|D_{t})=\mathbb{E}_{x~D_{t}}[e^{-y\alpha_{t}h_{t}(x)}]$。（这个损失函数就是加法模型学习思想的深刻体现）

如果还看书上的推导过程，依然有前面的问题，作者都是用向量来表示$x$，直接看推导过程很不直观。下面是改进的推导过程。

$$\mathbb{E}_{x~D_{t}}[e^{-y\alpha_{t}h_{t}(x)}]$$

$$=\sum_{i=1}^{n}P(X=x_{i})\mathbb{E}(e^{-y_{i}\alpha_{t}h_{t}(x_{i})}|x_{i})$$

$$=\sum_{i=1}^{N}D_{t}(x_{i})\mathbb{E}(e^{\alpha_{t}}\mathbb{I}(y_{i}\neq h_{t}(x))+e^{-\alpha_{t}}\mathbb{I}(y_{i}=f(x_{i}))|x_{i})$$

$$=\sum_{i=1}^{N}D_{t}(x_{i})(e^{\alpha_{t}}\mathbb{E}(\mathbb{I}(y_{i}\neq h_{t}(x_{i}))+ e^{-\alpha_{t}}\mathbb{E}(\mathbb{I}(y_{i}=h_{t}(x_{i})))$$

$$=\sum_{i=1}^{N}D_{t}(x_{i})(e^{\alpha_{t}}P(\mathbb{I}(y_{i}\neq h_{t}(x_{i}))|x_{i}) +e^{-\alpha_{t}}P(\mathbb{I}(y_{i}=h_{t}(x_{i}))))$$

$$=e^{\alpha_{t}}P_{x~D_{t}}(\mathbb{I}(y\neq h_{t}(x)))+e^{-\alpha_{t}}P_{x~D_{t}}(\mathbb{I}(y=h_{t}(x)))$$

其中$\epsilon_{t}=P_{x~D_{t}}(h_{t}(x)\neq f(x))$，$P_{x~D_{t}}(\dot)$也是一个符号，看了前面的内容应该知道表示什么。对上式求导得

$$\frac{\partial{l_{exp}(\alpha_{t}h_{t}|D_{t})}}{\partial{\alpha_{t}}}$$

$$=-e^{-\alpha_{t}}(1-\epsilon_{t}) + e^{\alpha_{t}}\epsilon_{t}$$

上式为0，得到

$$\alpha_{t}=\frac{1}{2}\ln{\frac{1-\epsilon_{t}}{\epsilon_{t}}}$$

如果用我前面提到的损失函数，依然会没法算出关于$\alpha$的权重更新公式，还是不知道为什么会这样。

### Update $D_{t}(x)$

这一部分书上写的很玄学，有很多骚操作，不过我自己推导了一下，发现这些书上的推导很多都是不必要的。比如那个泰勒展开有种故弄玄虚的感觉。所以书上的推导方法极为繁琐，而且让人不知所以然，不知道每一步做的原因。下面是我改进的推导。



基本思想还是一样的。要最小化损失函数（能想到这个损失函数很不容易），对损失函数做变换

$$l_{exp}(H_{t-1}+\alpha_{t}h_{t})=\mathbb{E}_{x~D}[e^{-y(H_{t-1}(x)+\alpha_{t}h_{t}(x))}]$$

$$=\mathbb{E}_{x~D}[e^{-yH_{t-1}(x)}e^{-y\alpha_{t}h_{t}(x)}]$$

其中$e^{-yH_{t}(x)}$可以看做常数，这是显然的，因为经过前面的参数学习过程，$H_{t-1}(x)$已经是确定下来的。下面讲上式展开，这样看起来形象一些，至少知道每一步具体在做些什么。

$$=\sum_{i=1}^{N}P(X=x_{i})\mathbb{E}(e^{-yH_{t-1}(x_{i})}e^{-y\alpha_{t}h_{t}(x_{i})}|x_{i})$$

$$=\sum_{i=1}^{N}D(x_{i})e^{-yH_{t-1}(x_{i})}\mathbb{E}(e^{-y\alpha_{t}h_{t}(x_{i})}|x_{i})$$

看到上面的公式应该很熟悉了，$x_{i}$的更新公式是什么样子的?

$$D_{t}(x_{i})=\frac{D(x_{i})e^{-yH_{t-1}(x_{i})}}{\sum_{x}D(x)e^{-yH_{t-1}(x)}}$$

这样很容易就可以写成$D_{t-1}$到$D_{t}$的更新公式。



不过上面的$D(x_{i})e^{-yH_{t-1}(x)}$为什么要变为一个概率（归一化）呢？我总结了下面几个观点

1. 表示成概率方便表示，损失函数可以一致的写成期望的形式。
2. 在后期的计算会控制数值大小，不至于造成溢出。
3. 写成概率形式对$\alpha_{t}$的更新没有影响（会被约掉）。



## Summary of AdaBoost

AdaBoost的总损失函数并不难写，思想也很简单。难得的是它的参数如何更新。使得AdaBoost能够学习的重要前提是加法模型的思想，用贪心思想，一次学习一个基学习器。



至于如何最小化损失函数有很强的技巧，其中用了两个损失函数$l_{exp}(\alpha_{t}h_{t}|D_{t})$和$l_{exp}(H_{t-1}+\alpha_{t}h_{t}|D)$，这两个看似差不多的函数，一个用来更新$\alpha_{t}$，这个方法仔细想还是会有些感觉的，它的损失函数就是算法学习过程中对应$t$步的损失函数（想想加法模型）；另一个用来更新$D_{t}(x)$，最让我没想到的是更新$D_{t}$的过程中，不是由$D_{t-1}$去推到$D_{t}$的，而是由$D$推到$D_{t}$，和我们平时遇到的数学习题很不一样，实在是很难想到的，我认为这是这个算法推导过程的精华，是很重要的技巧和思想。





